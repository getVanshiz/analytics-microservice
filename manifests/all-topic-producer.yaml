apiVersion: apps/v1
kind: Deployment
metadata:
  name: all-topics-producer
  namespace: team4
spec:
  replicas: 1
  selector:
    matchLabels:
      app: all-topics-producer
  template:
    metadata:
      labels:
        app: all-topics-producer
    spec:
      containers:
        - name: all-topics-producer
          image: python:3.9-slim
          command: ["bash", "-lc"]
          args:
            - |
              pip install --no-cache-dir \
                kafka-python \
                opentelemetry-api opentelemetry-sdk \
                opentelemetry-exporter-otlp-proto-grpc && \
              python - << 'PY'
              import json, time, uuid, os, random
              from collections import deque
              from datetime import datetime, timezone, timedelta
              from kafka import KafkaProducer

              # OpenTelemetry
              from opentelemetry import trace, propagate
              from opentelemetry.sdk.resources import Resource
              from opentelemetry.sdk.trace import TracerProvider
              from opentelemetry.sdk.trace.export import BatchSpanProcessor
              from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter

              BOOTSTRAP = os.getenv("KAFKA_BOOTSTRAP", "team4-kafka-kafka-bootstrap.team4.svc:9092")

              # For OTLP gRPC exporter, prefer host:port (no http://)
              OTLP_ENDPOINT = os.getenv(
                  "OTEL_EXPORTER_OTLP_ENDPOINT",
                  "otel-collector-opentelemetry-collector.monitoring.svc.cluster.local:4317"
              )
              SERVICE_NAME = os.getenv("OTEL_SERVICE_NAME", "all-topics-producer")
              RESOURCE_ATTRS = os.getenv("OTEL_RESOURCE_ATTRIBUTES", "team=team4,app=all-topics-producer")

              TOPICS = ["user-events", "order-events", "notification-events"]

              # ---- OTel init ----
              attrs = {}
              for pair in RESOURCE_ATTRS.split(","):
                  pair = pair.strip()
                  if pair and "=" in pair:
                      k, v = pair.split("=", 1)
                      attrs[k.strip()] = v.strip()

              resource = Resource.create({"service.name": SERVICE_NAME, **attrs})
              provider = TracerProvider(resource=resource)
              trace.set_tracer_provider(provider)

              exporter = OTLPSpanExporter(endpoint=OTLP_ENDPOINT, insecure=True)
              provider.add_span_processor(BatchSpanProcessor(exporter))
              tracer = trace.get_tracer("all-topics-producer")

              producer = KafkaProducer(
                  bootstrap_servers=[BOOTSTRAP],
                  value_serializer=lambda v: json.dumps(v).encode("utf-8"),
                  acks="all",
                  retries=5
              )

              IST = timezone(timedelta(hours=5, minutes=30))

              # ---- Correlation pools (for realistic cross-topic linking) ----
              recent_users = deque(maxlen=500)               # user_id strings like "user_1234"
              recent_orders = deque(maxlen=200)              # tuples: (order_id_uuid, user_id)

              def iso_ist_now():
                  dt = datetime.now(IST)
                  # Keep your original format (with trailing Z) to match consumer parsing:
                  return dt.isoformat(timespec="microseconds") + "Z"

              def occurred_at_format():
                  dt = datetime.now(IST)
                  return dt.strftime("%Y-%m-%d %H:%M:%S IST")

              def rand_user_id():
                  # Unified format used in all events
                  return f"user_{random.randint(1000, 9999)}"

              def make_user_event():
                  now = iso_ist_now()
                  user_id = rand_user_id()
                  # Track user in pool for downstream order/notification correlation
                  recent_users.append(user_id)
                  return {
                      "user_id": user_id,
                      "email": f"{user_id}@example.com",
                      "status": random.choice(["ACTIVE", "INACTIVE", "SUSPENDED"]),
                      "created_at": now,
                      "updated_at": now
                  }

              def make_order_event():
                  now = iso_ist_now()
                  # Prefer a real, recently-seen user; else create one and seed the pool
                  user_id = random.choice(list(recent_users)) if recent_users else rand_user_id()
                  if user_id not in recent_users:
                      recent_users.append(user_id)

                  order_id = str(uuid.uuid4())
                  # Keep for notifications to reference
                  recent_orders.append((order_id, user_id))

                  return {
                      "id": order_id,
                      "user_id": user_id,
                      "item": random.choice(["watch", "phone", "laptop", "shoes"]),
                      "quantity": random.randint(1, 5),
                      "note": random.choice(["fast", "gift wrap", "handle with care", ""]),
                      "status": random.choice(["CREATED", "CONFIRMED", "SHIPPED", "CANCELLED"]),
                      "created_at": now,
                      "updated_at": now
                  }

              def make_notification_event():
                  # Prefer to correlate to a real recent order 80% of the time
                  correlate = (len(recent_orders) > 0 and random.random() < 0.8)
                  if correlate:
                      order_id, user_id = random.choice(list(recent_orders))
                  else:
                      # Fallback: use a known user if we have one; otherwise synthesize
                      user_id = random.choice(list(recent_users)) if recent_users else rand_user_id()
                      order_id = str(uuid.uuid4())  # may not be known to consumer, but okay occasionally

                  channel = random.choice(["SMS", "EMAIL", "PUSH"])
                  stage_template = random.choice(["ORDER_CONFIRMED", "ORDER_SHIPPED", "ORDER_CANCELLED"])
                  status = random.choice(["SENT", "FAILED"])
                  msg = f"Your order {order_id} has been {stage_template.split('_',1)[1].lower()}."

                  return {
                      "event_name": "notification_sent" if status == "SENT" else "notification_failed",
                      "event_version": "1.0",
                      "event_id": str(uuid.uuid4()),
                      "occurred_at": occurred_at_format(),
                      "producer": "notification-service",
                      "data": {
                          "notification_id": f"notif_{random.randint(1000,9999)}",
                          "user_id": user_id,       # unified user_id format
                          "order_id": order_id,     # UUID (matches order id when correlated)
                          "channel": channel,
                          "template": stage_template,
                          "message": msg,
                          "status": status
                      }
                  }

              print("[producer] Producing schema-correct, *correlated* events with OTel tracing via Kafka headers")

              while True:
                  topic = random.choice(TOPICS)

                  if topic == "user-events":
                      payload = make_user_event()
                  elif topic == "order-events":
                      payload = make_order_event()
                  else:
                      payload = make_notification_event()

                  with tracer.start_as_current_span(
                      "kafka.produce",
                      attributes={
                          "messaging.system": "kafka",
                          "messaging.destination": topic,
                          "messaging.destination_kind": "topic",
                          "messaging.operation": "publish",
                      }
                  ) as span:
                      carrier = {}
                      propagate.inject(carrier)
                      headers = [(k, v.encode("utf-8")) for k, v in carrier.items()]

                      md = producer.send(topic, value=payload, headers=headers).get(timeout=10)

                      print(
                          f"[{topic}] sent offset={md.offset} partition={md.partition} "
                          f"otel_trace_id={format(span.get_span_context().trace_id, '032x')}",
                          flush=True
                      )

                  time.sleep(1)
              PY
          env:
            - name: KAFKA_BOOTSTRAP
              value: "team4-kafka-kafka-bootstrap.team4.svc:9092"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: "otel-collector-opentelemetry-collector.monitoring.svc.cluster.local:4317"
            - name: OTEL_SERVICE_NAME
              value: "all-topics-producer"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: "team=team4,app=all-topics-producer"
            - name: SCHEMA_MODE
              value: "legacy"